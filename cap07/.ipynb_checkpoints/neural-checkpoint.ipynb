{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCaH/DxlRI601cyj0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea60131748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def graph(formula, x_range):  \n",
    "    x = np.array(x_range)  \n",
    "    y = formula(x)  \n",
    "    plt.plot(x, y)  \n",
    "    plt.show() \n",
    "\n",
    "graph(lambda x: sigmoid(x), range(-6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "classi = \"\"\"\n",
    "    CREATE TABLE classi(\n",
    "       id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "       classe VARCHAR(50) NOT NULL\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "domande = \"\"\"\n",
    "CREATE TABLE domande(\n",
    "       id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "       domanda VARCHAR(255) NOT NULL,\n",
    "       id_classe INTEGER NOT NULL,\n",
    "       \n",
    "       FOREIGN KEY (id_classe) REFERENCES classi (id)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "risposte = \"\"\"\n",
    "    CREATE TABLE risposte(\n",
    "       id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "       risposta VARCHAR(255) NOT NULL,\n",
    "       id_classe INTEGER NOT NULL,\n",
    "       \n",
    "       FOREIGN KEY (id_classe) REFERENCES classi (id)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "# creo il db e mi ci connetto\n",
    "database = \"bot.db\"\n",
    "conn = sqlite3.connect(database)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# creo le tabelle\n",
    "for tabella in (classi, domande, risposte):\n",
    "    cursor.execute(tabella)\n",
    "    \n",
    "# scrivo i dati del file json\n",
    "with open(\"data.json\") as f:\n",
    "    data = json.load(f)\n",
    "    for elemento in data:\n",
    "        # aggiungo la classe se non esiste\n",
    "        q = \"INSERT INTO classi (classe) VALUES ('{}')\"\n",
    "        cursor.execute(q.format(elemento['classe']))\n",
    "        id_classe = cursor.lastrowid\n",
    "            \n",
    "        # aggiungo le domande\n",
    "        for domanda in elemento['domande']:\n",
    "            q = \"\"\"\n",
    "                INSERT INTO domande (domanda, id_classe)\n",
    "                VALUES\n",
    "                    (\"{0}\", \"{1}\")\n",
    "            \"\"\".format(domanda, id_classe)\n",
    "            cursor.execute(q)\n",
    "            \n",
    "        # e le risposte\n",
    "        for risposta in elemento['risposte']:\n",
    "            q = \"\"\"\n",
    "                INSERT INTO risposte (risposta, id_classe)\n",
    "                VALUES\n",
    "                    (\"{0}\", \"{1}\")\n",
    "            \"\"\".format(risposta, id_classe)\n",
    "            cursor.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['svilupp', 'svilupp', 'svilupp', 'svilupp', 'svilupp']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import ItalianStemmer\n",
    "stemmer = ItalianStemmer()\n",
    "\n",
    "parole = [\n",
    "    \"sviluppare\", \n",
    "    \"sviluppavo\", \n",
    "    \"sviluppa\", \n",
    "    \"sviluppate\", \n",
    "    \"sviluppiamo\"\n",
    "]\n",
    "\n",
    "temi = [stemmer.stem(parola) for parola in parole]\n",
    "print(temi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le stopwords sono: \n",
      "['per', 'questo', 'ebbero', 'più', 'nostri', 'delle', 'nostre']\n",
      "\n",
      "I termini significativi sono: \n",
      "['pauradei', 'discorsiche', 'facce']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('italian'))\n",
    "frase = \"per questo ebbero più paura\" +\\\n",
    "        \"dei nostri discorsi\" +\\\n",
    "        \"che delle nostre facce\"\n",
    "lista_parole = frase.split(\" \")\n",
    "rimosse = [w for w in lista_parole if w in stop]\n",
    "rimaste = [w for w in lista_parole if w not in stop]\n",
    "print(\"Le stopwords sono: \\n{}\\n\".format(rimosse))\n",
    "print(\"I termini significativi sono: \\n{}\".format(rimaste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import ItalianStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import string\n",
    "\n",
    "stemmer = ItalianStemmer()\n",
    "stop = set(stopwords.words('italian'))\n",
    "\n",
    "def elabora_corpus(corpus):\n",
    "    \"\"\"\n",
    "    corpus sarà una lista di tuple, formata da:\n",
    "    [\n",
    "        (\"una frase\", \"classe1\"),\n",
    "        (\"un'altra frase\", \"classe2\")\n",
    "    ]\n",
    "    \"\"\"\n",
    "    temi = set()\n",
    "    classi = set()\n",
    "    documenti = []\n",
    "    \n",
    "    stop = set(stopwords.words('italian'))\n",
    "    \n",
    "    for frase, classe in corpus:\n",
    "        # rimuovo le stopwords\n",
    "        parole = [\n",
    "            p.replace(\"?\", \"\").lower() for p in word_tokenize(frase) \n",
    "            if p not in stop\n",
    "            and p not in string.punctuation\n",
    "        ]\n",
    "        \n",
    "        temi.update(parole)\n",
    "        documenti.append((parole, classe))\n",
    "        classi.add(classe)\n",
    "\n",
    "    # creo i temi\n",
    "    temi = set(stemmer.stem(parola) for parola in temi)\n",
    "    return temi, classi, documenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alessandr', 'chiam', 'cia'},\n",
       " {'pippo'},\n",
       " [(['ciao', 'chiamo', 'alessandro'], 'pippo')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elabora_corpus([(\"Ciao, mi chiamo Alessandro\", \"pippo\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    SELECT domanda, classe\n",
    "    FROM domande\n",
    "    INNER JOIN classi ON (id_classe = classi.id)\n",
    "\"\"\"\n",
    "\n",
    "domande = cursor.execute(q).fetchall()\n",
    "temi, classi, documenti = elabora_corpus(domande)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di classi: 4\n",
      "Numero di documenti: 12\n",
      "Temi: \n",
      "{'piatt', 'sol', 'inform', \"all'apert\", 'pesc', 'disponibil', 'cred', 'cia', 'salv', 'mentr', 'escursion', 'contant', 'pos', 'poss', 'pag', 'durant', 'accett', 'tipic', 'cart', 'buongiorn', 'avet', \"qual'\", 'avre', 'bisogn', 'postepay'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero di classi: {}\".format(len(classi)))\n",
    "print(\"Numero di documenti: {}\".format(len(documenti)))\n",
    "print(\"Temi: \\n{}\".format(temi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "\n",
    "risultato = tf.multiply(x1, x2)\n",
    "\n",
    "print(risultato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 12 21 32]\n"
     ]
    }
   ],
   "source": [
    "sessione = tf.Session()\n",
    "print(sessione.run(risultato))\n",
    "sessione.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 12 21 32]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sessione:\n",
    "    writer = tf.summary.FileWriter('logs', sessione.graph)\n",
    "    print(sessione.run(risultato))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def crea_training_set(documenti, classi):\n",
    "    \"\"\"\n",
    "    Metodo che ritorna una tupla di due valori:\n",
    "        - l'array degli input (train_x)\n",
    "        - l'array degli output (train_y)\n",
    "        \n",
    "    I due array hanno lungezza fissa:\n",
    "     - len(train_x) == len(temi)\n",
    "     - len(train_y) == len(classi) \n",
    "    \"\"\"\n",
    "    training = []\n",
    "    output_vuota = [0] * len(classi)\n",
    "    classi = list(classi)\n",
    "\n",
    "    for parole, classe in documenti:\n",
    "        \n",
    "        temi_frase = [stemmer.stem(parola) for parola in parole]\n",
    "        \n",
    "        # riempio la lista di input\n",
    "        riga_input = [1 if t in temi_frase else 0 for t in temi]\n",
    "\n",
    "        # riepio la lista di output\n",
    "        riga_output = output_vuota[:]\n",
    "        riga_output[classi.index(classe)] = 1\n",
    "\n",
    "        training.append([riga_input, riga_output])\n",
    "\n",
    "    # mischio il mazzo\n",
    "    random.shuffle(training)\n",
    "    # trasformo in un array\n",
    "    training = np.array(training)\n",
    "\n",
    "    # e creo il training set\n",
    "    train_x = list(training[:,0])\n",
    "    train_y = list(training[:,1])\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temi = ['piatt', 'sol', 'inform', \"all'apert\", 'pesc', 'disponibil', 'cred', 'cia', 'salv', 'mentr', 'escursion', 'contant', 'pos', 'poss', 'pag', 'durant', 'accett', 'tipic', 'cart', 'buongiorn', 'avet', \"qual'\", 'avre', 'bisogn', 'postepay']\n",
      "Classi = ['introduzione', 'menu', 'pagamento_escursioni', 'pagamento']\n"
     ]
    }
   ],
   "source": [
    "print(\"Temi = {}\".format(list(temi)))\n",
    "print(\"Classi = {}\".format(list(classi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parole Documento = ['avete', 'disponibilità', 'pos', 'durante', 'escursioni']\n",
      "Classe Documento = pagamento_escursioni\n"
     ]
    }
   ],
   "source": [
    "print(\"Parole Documento = {}\".format(documenti[-1][0]))\n",
    "print(\"Classe Documento = {}\".format(documenti[-1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(crea_training_set([documenti[-1]], classi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]]\n",
      "y = [[0, 0, 0, 1], [0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "X, y = crea_training_set(documenti, classi)\n",
    "print(\"X = {}\".format(X))\n",
    "print(\"y = {}\".format(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tflearn import input_data, fully_connected, regression, DNN\n",
    "def BotANN(X, y):\n",
    "    \"\"\"\n",
    "    Questo metodo definisce e istruisce una \n",
    "    ANN (Artificial Neural Network), di tipo\n",
    "    DNN (Deep Neural Networl) composta da:\n",
    "        - un livello di input, \n",
    "        - due hidden layer,\n",
    "        - uno di output.\n",
    "    Utilizza softmax come funzione di attivazione.\n",
    "    \n",
    "    I parametri sono:\n",
    "       - X: array bidimensionale con i dati di input\n",
    "       - y: array bidimensionale con i dati di output\n",
    "       \n",
    "    Una volta definita la struttura della rete neurale,\n",
    "    ne viene fatto il training, e il modello viene\n",
    "    salvato in un file, chiamato \"rete.tflearn\".\n",
    "    \"\"\"\n",
    "    # resetto i dati del grafo\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Definire la Rete Neurale\n",
    "    rete = input_data(shape=[None, len(X[0])])\n",
    "    rete = fully_connected(rete, 8)\n",
    "    rete = fully_connected(rete, 8)\n",
    "    rete = fully_connected(rete, len(y[0]), activation='softmax')\n",
    "    rete = regression(rete)\n",
    "    \n",
    "    # Faccio il training\n",
    "    model = DNN(rete, tensorboard_dir='logs')\n",
    "    model.fit(X, y, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save('rete.tflearn')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1999  | total loss: \u001b[1m\u001b[32m0.08429\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1000 | loss: 0.08429 - acc: 0.9918 -- iter: 08/12\n",
      "Training Step: 2000  | total loss: \u001b[1m\u001b[32m0.07842\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 1000 | loss: 0.07842 - acc: 0.9926 -- iter: 12/12\n",
      "--\n",
      "INFO:tensorflow:/home/alessandro/Documents/book/machine_learning/src/neural/rete.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "modello = BotANN(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genera_temi(testo):\n",
    "    stop = set(stopwords.words('italian'))\n",
    "    lista_parole = word_tokenize(testo)\n",
    "    temi = [\n",
    "        stemmer.stem(p.lower()) for p in lista_parole\n",
    "        if p not in stop and p not in string.punctuation\n",
    "    ]\n",
    "    return temi\n",
    "\n",
    "def genera_input(lista_temi):\n",
    "    \n",
    "    lista_input = [0]*len(temi)  \n",
    "    for tema in lista_temi:\n",
    "        for i, t in enumerate(temi):\n",
    "            if t == tema: \n",
    "                lista_input[i] = 1\n",
    "    return(np.array(lista_input))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temi_frase = genera_temi(\"Ciao, mi chiamo Alessandro\")\n",
    "X = genera_input(temi_frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOGLIA_ERRORE = 0.25\n",
    "\n",
    "def classifica(modello, array):\n",
    "    # genera le probabilità \n",
    "    prob = modello.predict([array])[0]\n",
    "    # filtro quelle che superano la soglia\n",
    "    risultati = [\n",
    "        [i,p] for i,p in enumerate(prob) \n",
    "        if p > SOGLIA_ERRORE\n",
    "    ]\n",
    "    # ordino per le classi più probabili\n",
    "    risultati.sort(key=lambda x: x[1], reverse=True)\n",
    "    lista_classi = []\n",
    "    for r in risultati:\n",
    "        lista_classi.append((list(classi)[r[0]], r[1]))\n",
    "    return lista_classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rispondi(modello, frase):\n",
    "    temi_frase = genera_temi(frase)\n",
    "    X = genera_input(temi_frase)\n",
    "    classi_predette = classifica(modello, X)\n",
    "    \n",
    "    if classi_predette:\n",
    "        # leggo le risposte\n",
    "        q = \"\"\"\n",
    "            SELECT risposta \n",
    "            FROM risposte\n",
    "            INNER JOIN classi ON (risposte.id_classe = classi.id)\n",
    "            WHERE classe = '{0}'\n",
    "        \"\"\".format(classi_predette[0][0])\n",
    "        risposte = [r[0] for r in cursor.execute(q).fetchall()]\n",
    "        return np.random.choice(risposte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salve, serve aiuto?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rispondi(modello, \"C'è nessuno?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forniamo un'ampia scelta di piatti, guardi il menu direttamente sul sito [link]\n",
      "Oltre ai contanti, accettiamo VISA e Mastercard\n"
     ]
    }
   ],
   "source": [
    "print(rispondi(modello, \"Quali piatti consigliate oggi?\"))\n",
    "print(rispondi(modello, \"Posso pagarvi con soldi falsi?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contesti = \"\"\"\n",
    "CREATE TABLE contesti(\n",
    "       id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "       contesto VARCHAR(255) NOT NULL,\n",
    "       id_classe INTEGER NOT NULL,\n",
    "       \n",
    "       FOREIGN KEY (id_classe) REFERENCES classi (id)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "# aggiungo la tabella al db\n",
    "cursor.execute(contesti)\n",
    "\n",
    "# rileggo il file e aggiungo i contesti\n",
    "q_select = \"\"\"\n",
    "    SELECT id FROM classi\n",
    "    WHERE classe = '{}'\n",
    "\"\"\"\n",
    "\n",
    "q_insert = \"\"\"\n",
    "    INSERT INTO contesti (contesto, id_classe)\n",
    "    VALUES (\"{0}\", {1})\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# aggiungo l'ultima classe inserita\n",
    "pagamento_escursioni = data[-1]\n",
    "q = \"\"\"\n",
    "INSERT INTO classi (classe)\n",
    "VALUES (\"{}\")\n",
    "\"\"\".format(pagamento_escursioni['classe'])\n",
    "cursor.execute(q)\n",
    "\n",
    "id_classe = cursor.lastrowid\n",
    "for domanda in pagamento_escursioni['domande']:\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO domande (domanda, id_classe)\n",
    "        VALUES (\"{}\", {})\n",
    "        \"\"\".format(domanda, id_classe)\n",
    "    )\n",
    "for risposta in pagamento_escursioni['risposte']:\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO risposte (risposta, id_classe)\n",
    "        VALUES (\"{}\", {})\n",
    "        \"\"\".format(risposta, id_classe)\n",
    "    )\n",
    "    \n",
    "# aggiungo tutti i contesti\n",
    "for elemento in data:\n",
    "    if elemento.get('contesto'):\n",
    "        id_classe = cursor.execute(\n",
    "            q_select.format(elemento['classe'])\n",
    "        ).fetchone()[0]\n",
    "        cursor.execute(\n",
    "            q_insert.format(elemento['contesto'], id_classe)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contesti = {}\n",
    "\n",
    "def rispondi(modello, frase, utente=\"utente_prova\"):\n",
    "    temi_frase = genera_temi(frase)\n",
    "    X = genera_input(temi_frase)\n",
    "    classi_predette = classifica(modello, X)\n",
    "    # tolgo le probabilità\n",
    "    classi_predette = [c[0] for c in classi_predette]\n",
    "    \n",
    "    if classi_predette:\n",
    "        # ho un contesto settato?\n",
    "        if contesti.get(utente):\n",
    "            contesto = contesti[utente]\n",
    "            \n",
    "            # quali classi hanno questo contesto?\n",
    "            q = \"\"\"\n",
    "                SELECT classe FROM classi\n",
    "                INNER JOIN contesti ON (classi.id = contesti.id_classe)\n",
    "                WHERE classe IN ({})\n",
    "            \"\"\".format(\",\".join(\n",
    "                \"'{}'\".format(classe) for classe in classi_predette\n",
    "                )\n",
    "            )\n",
    "            filtro_classi = [c[0] for c in cursor.execute(q).fetchall()]\n",
    "            if filtro_classi:\n",
    "                # ho almeno una classe predetta che usa un contesto\n",
    "                classi_predette = [c for c in classi_predette]\n",
    "                \n",
    "        # leggo le risposte\n",
    "        q = \"\"\"\n",
    "            SELECT risposta \n",
    "            FROM risposte\n",
    "            INNER JOIN classi ON (risposte.id_classe = classi.id)\n",
    "            WHERE classe = '{0}'\n",
    "        \"\"\".format(classi_predette[0])\n",
    "        risposte = [r[0] for r in cursor.execute(q).fetchall()]\n",
    "        \n",
    "        # scelgo una risposta\n",
    "        risposta = np.random.choice(risposte)\n",
    "        \n",
    "        # imposto il contesto, se c'è\n",
    "        q = \"\"\"\n",
    "            SELECT contesto from contesti\n",
    "            INNER JOIN classi ON (contesti.id_classe = classi.id)\n",
    "            INNER JOIN risposte ON (risposte.id_classe = classi.id)\n",
    "            WHERE risposta = \"{}\"\n",
    "        \"\"\".format(risposta)\n",
    "        contesto = cursor.execute(q).fetchone()\n",
    "        if contesto:\n",
    "            contesti[utente] = contesto[0]\n",
    "            \n",
    "        return risposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forniamo un'ampia scelta di piatti, guardi il menu direttamente sul sito [link]\n",
      "{'utente_prova': 'ristorante'}\n",
      "Oltre ai contanti, accettiamo VISA e Mastercard\n",
      "Per questioni pratiche, accettiamo solo contanti, in quanto le escursioni sono all'aperto\n",
      "{'utente_prova': 'escursioni'}\n"
     ]
    }
   ],
   "source": [
    "print(rispondi(modello, \"Quali piatti consigliate oggi?\"))\n",
    "print(contesti)\n",
    "print(rispondi(modello, \"Posso pagare con carta di credito?\"))\n",
    "print(rispondi(modello, \"Avete un pos anche durante le escursioni?\"))\n",
    "print(contesti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "d = {\n",
    "    'temi': temi,\n",
    "    'classi': classi,\n",
    "    'documenti': documenti\n",
    "}\n",
    "\n",
    "pickle.dump(d, open(\"corpus.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
